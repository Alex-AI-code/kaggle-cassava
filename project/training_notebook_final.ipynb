{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow==2.3.2 in /opt/conda/lib/python3.7/site-packages (2.3.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (2.4.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (1.30.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.3.2) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.9.2->tensorflow==2.3.2) (46.1.3.post20200325)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.2) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.2) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.2) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.2) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.2) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.2) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.2) (0.4.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Install required libraries\n",
    "!pip install -U tensorflow==2.3.2\n",
    "!pip install --quiet /kaggle/input/kerasapplications #additional models\n",
    "!pip install --quiet /kaggle/input/efficientnet-git #efficientnet model for keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cloud-tpu-client in /opt/conda/lib/python3.7/site-packages (0.10)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /opt/conda/lib/python3.7/site-packages (from cloud-tpu-client) (1.8.0)\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.7/site-packages (from cloud-tpu-client) (4.1.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.3)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.14.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.14.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.17.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from oauth2client->cloud-tpu-client) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from oauth2client->cloud-tpu-client) (0.2.7)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (46.1.3.post20200325)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (3.1.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2019.3)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.51.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.6.20)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###Get required libraries for TPU\n",
    "!pip install cloud-tpu-client\n",
    "import tensorflow as tf \n",
    "from cloud_tpu_client import Client\n",
    "Client().configure_tpu_version(tf.__version__, restart_type='ifNeeded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "_cell_guid": "6e283b85-2177-4105-bc80-ecf576db7083",
    "_uuid": "aeec83f6-c83a-43f9-8f11-55a573f7836c"
   },
   "outputs": [],
   "source": [
    "###More imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "from collections import namedtuple\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout,\\\n",
    "        Flatten,GlobalAveragePooling2D,BatchNormalization, Activation\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '../input/cassava-leaf-disease-classification/' #Set our data directory \n",
    "os.listdir(main_dir) #List files in our directory\n",
    "train_img_path = '../input/cassava-leaf-disease-classification/train_images' #point to training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU grpc://10.0.0.2:8470\n",
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "###Set up kaggle TPU's\n",
    "\n",
    "###Try to connect to our TPU\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() #Set up our TPU\n",
    "    print(f'Running on TPU {tpu.master()}')\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "###Configure the notebook to use the TPU or lackthereof \n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu) \n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "REPLICAS = strategy.num_replicas_in_sync #Check how many simultaneous processes our TPU can handle\n",
    "print(f'REPLICAS: {REPLICAS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE #keras optimization of value \n",
    "\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification') #Set google cloud storage data path for our default dataset\n",
    "GCS_NewTFPure512 = KaggleDatasets().get_gcs_path('cassava-leaf-disease-tfrecords-512x512')# using a cleaned dataset posted by another member on kaggle        \n",
    "\n",
    "\n",
    "###Data paramaters\n",
    "IMAGE_SIZE = [512,512]\n",
    "CLASSES = ['0', '1', '2', '3', '4']\n",
    "\n",
    "###Model runtime paramaters, number of folds and early stopping\n",
    "N_FOLDS = 5\n",
    "PATIENCE = 15 \n",
    "PATIENT = 10\n",
    "\n",
    "SEED = 100\n",
    "MODEL_NAME = \"EfficentNetB3\"\n",
    "\n",
    "###More image paramaters\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "HEIGHT_RS = 512\n",
    "WIDTH_RS = 512\n",
    "CHANNELS = 3\n",
    "N_CLASSES = 5\n",
    "\n",
    "###BiTemperedLoss function paramaters\n",
    "T_1 = 0.6\n",
    "T_2 = 1.4\n",
    "SMOOTH_FRACTION = 0.1\n",
    "N_ITER = 5\n",
    "\n",
    "#Model variables\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "EPOCHS = 30\n",
    "input_shape = (512,512,3)\n",
    "dropout_rate = 0.2\n",
    "\n",
    "MODEL_SAVE_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of the CSV file \n",
      "\n",
      "          image_id  label\n",
      "0  1000015157.jpg      0\n",
      "1  1000201771.jpg      3\n",
      "2   100042118.jpg      1\n",
      "3  1000723321.jpg      1\n",
      "4  1000812911.jpg      3\n",
      "\n",
      " Lenght of the image label :  21397\n",
      "\n",
      " length of the image id : 21397\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(main_dir+'train.csv') #Load our directory into a pd dataframe\n",
    "\n",
    "imgs_id = dataframe['image_id'].values#Store image ids and labels\n",
    "imgs_label = dataframe['label'].values\n",
    "print('Head of the CSV file \\n\\n',dataframe.head())\n",
    "print('\\n Lenght of the image label : ',len(dataframe['label']))\n",
    "print('\\n length of the image id :', len(dataframe['image_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train04-1427.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train08-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train12-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train13-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train06-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train07-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train10-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train02-1427.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train14-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train05-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train03-1427.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train11-1426.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train01-1427.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train00-1427.tfrec',\n",
       " 'gs://kds-8b25f1242ebf8f91e8a1586f4f6a2751c4cf20c6c29316583a4dcf36/Id_train09-1426.tfrec']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATASET_FILENAMES = tf.io.gfile.glob(GCS_NewTFPure512 + '/Id_train*.tfrec')#Store our training dataset filenames in a list\n",
    "\n",
    "NUM_FILES = len(DATASET_FILENAMES)\n",
    "np.random.shuffle(DATASET_FILENAMES)#Shuffle the training data to allow for a better distrubition\n",
    "display(DATASET_FILENAMES)\n",
    "\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test_tfrecords/ld_test00-1.tfrec')#Only 1 test file given to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"8ec34a63-fd07-43ef-bf62-400af2ded700\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"8ec34a63-fd07-43ef-bf62-400af2ded700\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '8ec34a63-fd07-43ef-bf62-400af2ded700',\n",
       "                        [{\"domain\": {\"x\": [0.0, 1.0], \"y\": [0.0, 1.0]}, \"hovertemplate\": \"Label=%{label}<br>Number of Observations=%{value}<extra></extra>\", \"labels\": [3, 4, 2, 1, 0], \"legendgroup\": \"\", \"name\": \"\", \"showlegend\": true, \"type\": \"pie\", \"values\": [13158, 2577, 2386, 2189, 1087]}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"piecolorway\": [\"rgb(0,68,27)\", \"rgb(0,109,44)\", \"rgb(35,139,69)\", \"rgb(65,171,93)\", \"rgb(116,196,118)\", \"rgb(161,217,155)\", \"rgb(199,233,192)\", \"rgb(229,245,224)\", \"rgb(247,252,245)\"], \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Distribution of Labels in the Training Dataset\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8ec34a63-fd07-43ef-bf62-400af2ded700');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly_express as px\n",
    "\n",
    "labelCounts = dataframe['label'].value_counts().reset_index()\n",
    "labelCounts.columns = ['Label', 'Number of Observations']\n",
    "\n",
    "# Plotting a Pie Chart to show the Distribution\n",
    "fig = px.pie(labelCounts, \n",
    "             names = 'Label',values='Number of Observations', \n",
    "             labels = CLASSES, \n",
    "             title = 'Distribution of Labels in the Training Dataset',\n",
    "             color_discrete_sequence=px.colors.sequential.Greens_r)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions - data augmention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation @cdeotte kernel: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n",
    "def transform_rotation(image, height, rotation):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly rotated\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    rotation = rotation * tf.random.uniform([1],dtype='float32')\n",
    "    # CONVERT DEGREES TO RADIANS\n",
    "    rotation = math.pi * rotation / 180.\n",
    "    \n",
    "    # ROTATION MATRIX\n",
    "    c1 = tf.math.cos(rotation)\n",
    "    s1 = tf.math.sin(rotation)\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    rotation_matrix = tf.reshape(tf.concat([c1,s1,zero, -s1,c1,zero, zero,zero,one],axis=0),[3,3])\n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(rotation_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "def transform_shear(image, height, shear):\n",
    "    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n",
    "    # output - image randomly sheared\n",
    "    DIM = height\n",
    "    XDIM = DIM%2 #fix for size 331\n",
    "    \n",
    "    shear = shear * tf.random.uniform([1],dtype='float32')\n",
    "    shear = math.pi * shear / 180.\n",
    "        \n",
    "    # SHEAR MATRIX\n",
    "    one = tf.constant([1],dtype='float32')\n",
    "    zero = tf.constant([0],dtype='float32')\n",
    "    c2 = tf.math.cos(shear)\n",
    "    s2 = tf.math.sin(shear)\n",
    "    shear_matrix = tf.reshape(tf.concat([one,s2,zero, zero,c2,zero, zero,zero,one],axis=0),[3,3])    \n",
    "\n",
    "    # LIST DESTINATION PIXEL INDICES\n",
    "    x = tf.repeat( tf.range(DIM//2,-DIM//2,-1), DIM )\n",
    "    y = tf.tile( tf.range(-DIM//2,DIM//2),[DIM] )\n",
    "    z = tf.ones([DIM*DIM],dtype='int32')\n",
    "    idx = tf.stack( [x,y,z] )\n",
    "    \n",
    "    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n",
    "    idx2 = K.dot(shear_matrix,tf.cast(idx,dtype='float32'))\n",
    "    idx2 = K.cast(idx2,dtype='int32')\n",
    "    idx2 = K.clip(idx2,-DIM//2+XDIM+1,DIM//2)\n",
    "    \n",
    "    # FIND ORIGIN PIXEL VALUES \n",
    "    idx3 = tf.stack( [DIM//2-idx2[0,], DIM//2-1+idx2[1,]] )\n",
    "    d = tf.gather_nd(image, tf.transpose(idx3))\n",
    "        \n",
    "    return tf.reshape(d,[DIM,DIM,3])\n",
    "\n",
    "# CutOut\n",
    "def data_augment_cutout(image, min_mask_size=(int(HEIGHT * .1), int(HEIGHT * .1)), \n",
    "                        max_mask_size=(int(HEIGHT * .125), int(HEIGHT * .125))):\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    if p_cutout > .85: # 10~15 cut outs\n",
    "        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .6: # 5~10 cut outs\n",
    "        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .25: # 2~5 cut outs\n",
    "        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    else: # 1 cut out\n",
    "        image = random_cutout(image, HEIGHT, WIDTH, \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n",
    "\n",
    "    return image\n",
    "\n",
    "def random_cutout(image, height, width, channels=3, min_mask_size=(10, 10), max_mask_size=(80, 80), k=1):\n",
    "    assert height > min_mask_size[0]\n",
    "    assert width > min_mask_size[1]\n",
    "    assert height > max_mask_size[0]\n",
    "    assert width > max_mask_size[1]\n",
    "\n",
    "    for i in range(k):\n",
    "      mask_height = tf.random.uniform(shape=[], minval=min_mask_size[0], maxval=max_mask_size[0], dtype=tf.int32)\n",
    "      mask_width = tf.random.uniform(shape=[], minval=min_mask_size[1], maxval=max_mask_size[1], dtype=tf.int32)\n",
    "\n",
    "      pad_h = height - mask_height\n",
    "      pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n",
    "      pad_bottom = pad_h - pad_top\n",
    "\n",
    "      pad_w = width - mask_width\n",
    "      pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n",
    "      pad_right = pad_w - pad_left\n",
    "\n",
    "      cutout_area = tf.zeros(shape=[mask_height, mask_width, channels], dtype=tf.uint8)\n",
    "\n",
    "      cutout_mask = tf.pad([cutout_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n",
    "      cutout_mask = tf.squeeze(cutout_mask, axis=0)\n",
    "      image = tf.multiply(tf.cast(image, tf.float32), tf.cast(cutout_mask, tf.float32))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data augmentation function, can be used in the place of functions in the cell above, this one applies random transformations\n",
    "###to our data\n",
    "\n",
    "def data_augment(image, label):\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "#     # Shear\n",
    "#     if p_shear > .2:\n",
    "#         if p_shear > .6:\n",
    "#             image = transform_shear(image, HEIGHT, shear=20.)\n",
    "#         else:\n",
    "#             image = transform_shear(image, HEIGHT, shear=-20.)\n",
    "            \n",
    "    # Rotation\n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, HEIGHT, rotation=-45.)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "#     if p_spatial > .75:\n",
    "#         image = tf.image.transpose(image)\n",
    "        \n",
    "#     # Rotates\n",
    "#     if p_rotate > .75:\n",
    "#         image = tf.image.rot90(image, k=3) # rotate 270º\n",
    "#     elif p_rotate > .5:\n",
    "#         image = tf.image.rot90(image, k=2) # rotate 180º\n",
    "#     elif p_rotate > .25:\n",
    "#         image = tf.image.rot90(image, k=1) # rotate 90º\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    if p_pixel_1 >= .4:\n",
    "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
    "    if p_pixel_2 >= .4:\n",
    "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
    "    if p_pixel_3 >= .4:\n",
    "        image = tf.image.random_brightness(image, max_delta=.1)\n",
    "        \n",
    "#     # Crops\n",
    "#     if p_crop > .6:\n",
    "#         if p_crop > .9:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.5)\n",
    "#         elif p_crop > .8:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.6)\n",
    "#         elif p_crop > .7:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.7)\n",
    "#         else:\n",
    "#             image = tf.image.central_crop(image, central_fraction=.8)\n",
    "#     elif p_crop > .3:\n",
    "#         crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n",
    "#         image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n",
    "            \n",
    "    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n",
    "\n",
    "    if p_cutout > .5:\n",
    "        image = data_augment_cutout(image)\n",
    "        \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions - loading and preparing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    " ###One hot encoding of the data https://en.wikipedia.org/wiki/One-hot\n",
    "\n",
    "def one_hot(image, label):\n",
    "    label = tf.one_hot(label, len(CLASSES), dtype = tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode the data\n",
    "#turn the images into tensors\n",
    "#normalize the image (get every pixel to have a value between 0 and 1)\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up variables X and y; in this case image and prediction (for images with no label)\n",
    "def read_tfrecord(example, labeled):\n",
    "    tfrecord_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    } if labeled else {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    if labeled:\n",
    "        label = tf.cast(example['target'], tf.int32)\n",
    "        return image, label\n",
    "    idnum = example['image_name']\n",
    "    return image, idnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following code will load the dataset using the TPU\n",
    "#IF load dataset is used comment out the other code block below\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(partial(read_tfrecord, labeled=labeled), num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following functions will be used to load our training, validation, and test datasets, as well as print out the number of images in each dataset.\n",
    "#If this codeblock is used commment out above codeblock\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)  \n",
    "    dataset = dataset.map(one_hot, num_parallel_calls=AUTOTUNE)  #Map our one hot encoded dataset using keras optimizer\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)  #Map our augmeneted dataset\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)#Shuffle the dataset\n",
    "    dataset = dataset.batch(BATCH_SIZE)#Set the batch size of our data\n",
    "    dataset = dataset.prefetch(AUTOTUNE)#Allow later parts of the dataset to be processed while the current element is being processed\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALID_FILENAMES, labeled=True, ordered=ordered) \n",
    "    dataset = dataset.map(one_hot, num_parallel_calls=AUTOTUNE) \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.map(one_hot, num_parallel_calls=AUTOTUNE) \n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "\n",
    "\n",
    "# NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "# NUM_VALIDATION_IMAGES = count_data_items(VALID_FILENAMES)\n",
    "# NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "\n",
    "\n",
    "# print('Dataset: {} training images, {} validation images, {} (unlabeled) test images'.format(\n",
    "#     NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module we'll need to import our custom module\n",
    "from shutil import copyfile\n",
    "\n",
    "# copy our file into the working directory (make sure it has .py suffix)\n",
    "copyfile(src = \"../input/bitempered-logistic-loss-tensorflow-v2/bi_tempered_loss.py\", dst = \"../working/loss.py\")\n",
    "\n",
    "# import all our functions\n",
    "from loss import bi_tempered_logistic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiTemperedLogisticLoss(tf.keras.losses.Loss):\n",
    "  def __init__(self, t1, t2, lbl_smth, n_iter):\n",
    "    super(BiTemperedLogisticLoss, self).__init__() #add our class to the keras classes, allowing us to call on it\n",
    "    self.t1 = t1\n",
    "    self.t2 = t2\n",
    "    self.lbl_smth = lbl_smth\n",
    "    self.n_iter = n_iter\n",
    "\n",
    "  def call(self, y_true, y_pred):#method to return our loss function\n",
    "    return bi_tempered_logistic_loss(y_pred, y_true, self.t1, self.t2, self.lbl_smth, self.n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn\n",
    "\n",
    "with strategy.scope():\n",
    "    class LRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):#Cyclical learning rrate\n",
    "        def __call__(self, step):\n",
    "            return lrfn(epoch=step//STEPS_PER_EPOCH)#Modify the learning rate at each epoch\n",
    "    ###Our model function    \n",
    "    def get_model():\n",
    "        #Set our base model, using weights from an online database\n",
    "        conv_base = efn.EfficientNetB3(weights='noisy-student', include_top = False, input_shape = input_shape)\n",
    "        conv_base.trainable = True#Set our base model to be trainable, which allows it to update its weights\n",
    "    \n",
    "        model = models.Sequential()#Create our sequential model and add extra layers to our base model\n",
    "        model.add(conv_base)\n",
    "        model.add(layers.GlobalAveragePooling2D(name=\"gap\"))#Add pooling to our model, downscaling our image as it passes through this layer\n",
    "        model.add(layers.Dense(16, activation=\"relu\", name=\"intermediate\"))#Add an additonal dense layer to our model\n",
    "        model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))#Add dropout to our model, turning off neurons increasing training efficiency, 0.5 was chosen as it is the most random\n",
    "        model.add(layers.Dense(5, activation=\"softmax\", name=\"fc_out\"))#Final dense layer with neurons for each label\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam()#optimizer for compiling the model\n",
    "        \n",
    "        #Set our bitempered loss function parameters\n",
    "        T_1 = 0.6\n",
    "        T_2 = 1.4\n",
    "        SMOOTH_FRACTION = 0.1\n",
    "        N_ITER = 5\n",
    "        \n",
    "        model.compile(optimizer=optimizer, \n",
    "                      loss=BiTemperedLogisticLoss(t1=T_1, t2=T_2, lbl_smth=SMOOTH_FRACTION, n_iter=N_ITER), \n",
    "                      metrics=['categorical_accuracy'])#Compile the model using our specified paramaters and loss function\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate schedule: 1e-05 to 1e-05 to 1e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Cyclical learning rate paramaters\n",
    "LR_START = 0.00001#Starting learning rate\n",
    "LR_MAX = 0.00005 * strategy.num_replicas_in_sync#Max learning rate, based on number of TPU cores\n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = 5 #When to increase LR \n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_EXP_DECAY = .8 # LR decay, mimicking a typical LR function\n",
    "        \n",
    "###Function to decide how to change the larning rate, should be done using a triangular cyclical learning rate\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) \n",
    "    return lr\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "def get_checkpoint(model_save_path):\n",
    "    return ModelCheckpoint(model_save_path, \n",
    "                             monitor= 'val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=False, \n",
    "                             mode= 'min', \n",
    "                             save_weights_only = False)\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "def get_early_stopping():\n",
    "    return EarlyStopping(monitor = 'val_loss', min_delta = 0.0001, \n",
    "                           patience = PATIENCE, mode = 'min', verbose = 1,\n",
    "                           restore_best_weights = True)\n",
    "    \n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\n",
    "def get_learning_rate_decay():\n",
    "  return ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, \n",
    "                              patience = 1, min_delta = 0.0001, \n",
    "                              mode = 'min', verbose = 1)\n",
    "\n",
    "###Model callback function to allow us to tune paramaters while training is happening, such as LR\n",
    "def get_model_callback( fold_num):\n",
    "    model_save_path_last = f'{MODEL_NAME}_last_fold_{fold_num}_.h5'\n",
    "    print(\"Last model save path: \", model_save_path_last)\n",
    "    \n",
    "#saves the most recent model\n",
    "    checkpoint_last = get_checkpoint(model_save_path_last)\n",
    "\n",
    "    early_stopping = get_early_stopping()\n",
    "#     learning_rate_decay = get_learning_rate_decay()\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "    return [checkpoint_last, early_stopping, lr_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Fold:  0\n",
      "Train File:  17116\n",
      "Valid File:  4279\n",
      "Last model save path:  EfficentNetB3_last_fold_0_.h5\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6178 - categorical_accuracy: 0.4865\n",
      "Epoch 00001: saving model to EfficentNetB3_last_fold_0_.h5\n",
      "133/133 [==============================] - 93s 700ms/step - loss: 0.6178 - categorical_accuracy: 0.4865 - val_loss: 0.6219 - val_categorical_accuracy: 0.6063\n",
      "Start Fold:  1\n",
      "Train File:  17115\n",
      "Valid File:  4280\n",
      "Last model save path:  EfficentNetB3_last_fold_1_.h5\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6084 - categorical_accuracy: 0.5507\n",
      "Epoch 00001: saving model to EfficentNetB3_last_fold_1_.h5\n",
      "133/133 [==============================] - 78s 589ms/step - loss: 0.6084 - categorical_accuracy: 0.5507 - val_loss: 0.6244 - val_categorical_accuracy: 0.5215\n",
      "Start Fold:  2\n",
      "Train File:  17117\n",
      "Valid File:  4278\n",
      "Last model save path:  EfficentNetB3_last_fold_2_.h5\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6131 - categorical_accuracy: 0.5302\n",
      "Epoch 00001: saving model to EfficentNetB3_last_fold_2_.h5\n",
      "133/133 [==============================] - 78s 587ms/step - loss: 0.6131 - categorical_accuracy: 0.5302 - val_loss: 0.6135 - val_categorical_accuracy: 0.5514\n",
      "Start Fold:  3\n",
      "Train File:  17115\n",
      "Valid File:  4280\n",
      "Last model save path:  EfficentNetB3_last_fold_3_.h5\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6074 - categorical_accuracy: 0.5717\n",
      "Epoch 00001: saving model to EfficentNetB3_last_fold_3_.h5\n",
      "133/133 [==============================] - 81s 611ms/step - loss: 0.6074 - categorical_accuracy: 0.5717 - val_loss: 0.6176 - val_categorical_accuracy: 0.5999\n",
      "Start Fold:  4\n",
      "Train File:  17117\n",
      "Valid File:  4278\n",
      "Last model save path:  EfficentNetB3_last_fold_4_.h5\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6014 - categorical_accuracy: 0.5446\n",
      "Epoch 00001: saving model to EfficentNetB3_last_fold_4_.h5\n",
      "133/133 [==============================] - 83s 621ms/step - loss: 0.6014 - categorical_accuracy: 0.5446 - val_loss: 0.5993 - val_categorical_accuracy: 0.6288\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)#Set up our kfold crossvalidation\n",
    "\n",
    "for fold , (X_train, X_valid) in enumerate(skf.split(np.arange(NUM_FILES))):\n",
    "\n",
    "    print(\"Start Fold: \",fold);\n",
    "\n",
    "    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    \n",
    "    TRAINING_FILENAMES = [DATASET_FILENAMES[x] for x in X_train] #Assign training data per fold that was split in the for loop\n",
    "    VALID_FILENAMES = [DATASET_FILENAMES[x] for x in X_valid]\n",
    "        \n",
    "    ct_train = count_data_items(TRAINING_FILENAMES)#Count our training data\n",
    "    ct_valid = count_data_items(VALID_FILENAMES)\n",
    "\n",
    "    print(\"Train File: \",ct_train)\n",
    "    print(\"Valid File: \", ct_valid)\n",
    "\n",
    "    STEPS_PER_EPOCH =  ct_train// BATCH_SIZE \n",
    "    VALIDATION_STEPS = ct_valid // BATCH_SIZE\n",
    "    \n",
    "    callback_list = get_model_callback(fold) #Save our previous models\n",
    "\n",
    "    tf.keras.backend.clear_session()#Clear our previous model paramaters\n",
    "        \n",
    "    with strategy.scope():# Fit the model\n",
    "        model = get_model()\n",
    "        history = model.fit( x=get_training_dataset(),#Get  data after each loop, since each paramater will change\n",
    "                                steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                                epochs = EPOCHS,\n",
    "                                validation_data = get_validation_dataset(), \n",
    "                                validation_steps = VALIDATION_STEPS,\n",
    "                                callbacks = callback_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
